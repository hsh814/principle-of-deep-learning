{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_kg_hide-output": true,
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-05-07T05:18:16.368443Z",
          "iopub.status.busy": "2023-05-07T05:18:16.367979Z",
          "iopub.status.idle": "2023-05-07T05:18:16.385047Z",
          "shell.execute_reply": "2023-05-07T05:18:16.383109Z",
          "shell.execute_reply.started": "2023-05-07T05:18:16.368402Z"
        },
        "id": "GHCHbx1v7cYg",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Code from https://github.com/xprathamesh/Spoiler-Detection-in-Movie-Reviews/blob/master/MaLSTM-Spoiler-Detection.ipynb\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SOjbBvs8SWf",
        "outputId": "cada567a-b510-48b9-f1c8-a909c88428bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 1078, in _pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\n",
            "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 297, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
            "  File \"/opt/conda/envs/alpha/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 1976, in do_wait_suspend\n",
            "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
            "  File \"/opt/conda/envs/alpha/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2011, in _do_wait_suspend\n",
            "    time.sleep(0.01)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/root/lstm/malstm_imdb.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcure.unist.duckdns.org/root/lstm/malstm_imdb.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcure.unist.duckdns.org/root/lstm/malstm_imdb.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1363\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1740\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1087\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1078\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:297\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/opt/conda/envs/alpha/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:1976\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   1973\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   1975\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[0;32m-> 1976\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   1978\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1980\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   1981\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/alpha/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2011\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_mpl_hook()\n\u001b[1;32m   2010\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2011\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2013\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2015\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-07T05:18:20.533171Z",
          "iopub.status.busy": "2023-05-07T05:18:20.531890Z",
          "iopub.status.idle": "2023-05-07T05:18:32.494018Z",
          "shell.execute_reply": "2023-05-07T05:18:32.492538Z",
          "shell.execute_reply.started": "2023-05-07T05:18:20.533108Z"
        },
        "id": "Bd8a6g1b7cYn",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/root/lstm/malstm_imdb.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcure.unist.duckdns.org/root/lstm/malstm_imdb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mdatetime\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39margparse\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mcsv\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mitertools\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mrandom\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcure.unist.duckdns.org/root/lstm/malstm_imdb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mimport\u001b[39;00m exit\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bcure.unist.duckdns.org/root/lstm/malstm_imdb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnltk\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mtensorflow\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcure.unist.duckdns.org/root/lstm/malstm_imdb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bcure.unist.duckdns.org/root/lstm/malstm_imdb.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ],
      "source": [
        "import os, datetime, argparse, csv, itertools, random\n",
        "from sys import exit\n",
        "import nltk, tensorflow\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from math import exp\n",
        "from re import sub\n",
        "from time import time\n",
        "from random import shuffle\n",
        "\n",
        "from gensim.models import KeyedVectors\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import tkinter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-05-07T05:18:32.497904Z",
          "iopub.status.busy": "2023-05-07T05:18:32.497104Z",
          "iopub.status.idle": "2023-05-07T05:18:32.509083Z",
          "shell.execute_reply": "2023-05-07T05:18:32.507659Z",
          "shell.execute_reply.started": "2023-05-07T05:18:32.497861Z"
        },
        "id": "VB4TY4KV7cYn",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, GRU, Bidirectional, Dense, Dropout, Concatenate, Lambda\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adadelta, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0vjFC0evNBso"
      },
      "outputs": [],
      "source": [
        "# Unzip dataset https://www.kaggle.com/datasets/rmisra/imdb-spoiler-dataset\n",
        "# !unzip /content/drive/MyDrive/UNIST/deep-learning/imdb-spoiler-dataset.zip -d /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "_kg_hide-output": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-05-07T05:18:32.511099Z",
          "iopub.status.busy": "2023-05-07T05:18:32.510739Z",
          "iopub.status.idle": "2023-05-07T05:18:52.929463Z",
          "shell.execute_reply": "2023-05-07T05:18:52.927932Z",
          "shell.execute_reply.started": "2023-05-07T05:18:32.511066Z"
        },
        "id": "2qkJqQ9H7cYo",
        "outputId": "2a04c228-f844-4504-feab-fe3de9dc939e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "nltk.download('stopwords')\n",
        "preprocessed_file = '/content/drive/MyDrive/UNIST/deep-learning/preprocessed.csv'\n",
        "if not os.path.exists(preprocessed_file):\n",
        "    review_file = '/content/data/IMDB_reviews.json'\n",
        "    review_data = pd.read_json(review_file, lines = True)\n",
        "    review_data.head()\n",
        "    movie_file = '/content/data/IMDB_movie_details.json'\n",
        "    movie_data = pd.read_json(movie_file, lines = True)\n",
        "    movie_map = dict()\n",
        "    # movie_list = movie_data.\n",
        "    movie_synopses = pd.Series([str(synopsis) for synopsis in movie_data['plot_synopsis']])\n",
        "    movie_summary = pd.Series([re.split('\\s*Written by\\s*\\n', \n",
        "                                          str(plot))[0] for plot in movie_data['plot_summary']])\n",
        "    movie_info = pd.Series([movie_synopses[i] \\\n",
        "                                        if len(movie_synopses[i]) > len(movie_summary[i]) else movie_summary[i] \\\n",
        "                                        for i in range(len(movie_synopses))])\n",
        "    movie_ids = pd.Series(movie_data['movie_id'])\n",
        "    movie_data.head()\n",
        "    m_info = list(movie_info)\n",
        "    m_ids = list(movie_ids)\n",
        "    for minfo, mid in zip(m_info, m_ids):\n",
        "        movie_map[str(mid)] = minfo\n",
        "    tmp_list = list()\n",
        "    for movie_id in list(review_data[\"movie_id\"]):\n",
        "        if movie_id not in movie_map:\n",
        "            print(f\"{movie_id} not in map\")\n",
        "            tmp_list.append(\"No synopsis\")\n",
        "            continue\n",
        "        movie_info = movie_map[str(movie_id)]\n",
        "        tmp_list.append(movie_info)\n",
        "    input_data = pd.DataFrame({\"review\": review_data[\"review_text\"], \"synopsis\": tmp_list, 'label': review_data[\"is_spoiler\"]})\n",
        "    input_data.to_csv(\"/content/drive/MyDrive/UNIST/deep-learning/preprocessed.csv\", index=False)\n",
        "    input_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-05-07T05:48:05.961240Z",
          "iopub.status.busy": "2023-05-07T05:48:05.960595Z",
          "iopub.status.idle": "2023-05-07T05:48:06.159245Z",
          "shell.execute_reply": "2023-05-07T05:48:06.157838Z",
          "shell.execute_reply.started": "2023-05-07T05:48:05.961194Z"
        },
        "id": "OG04COHD7cYz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# rows_count  = 300000\n",
        "rows_count  = 100000\n",
        "test_ratio  = 0.80 # divide into train and test data\n",
        "train_ratio = 0.90 # divide into train and validation data\n",
        "random_state = 200\n",
        "max_len     = 30\n",
        "vocab_size  = 1\n",
        "vocab_limit = None\n",
        "\n",
        "data_name     = 'movie_training'\n",
        "sequence_cols = ['synopsis', 'review']\n",
        "score_col     = ['label']\n",
        "\n",
        "x_train, y_train  = list(), list()\n",
        "x_val, y_val      = list(), list()\n",
        "x_test, y_test    = list(), list()\n",
        "\n",
        "vocab       = set('PAD')\n",
        "word_to_id  = {'PAD':0}\n",
        "id_to_word  = {0:'PAD'}\n",
        "\n",
        "word_to_count = dict()\n",
        "# Split data into train and test sets\n",
        "# train_data, test_data, train_label, test_label = train_test_split(input_data, label, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2023-05-07T05:20:11.333137Z",
          "iopub.status.busy": "2023-05-07T05:20:11.332103Z",
          "iopub.status.idle": "2023-05-07T05:20:11.401968Z",
          "shell.execute_reply": "2023-05-07T05:20:11.400538Z",
          "shell.execute_reply.started": "2023-05-07T05:20:11.332985Z"
        },
        "id": "8U371hoQ7cYp",
        "outputId": "0fef1904-1b8d-4975-eaa9-815f0b58bc3b",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f0bee1f8-68a1-4bea-a1ea-bced9c567c93\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>synopsis</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In its Oscar year, Shawshank Redemption (writt...</td>\n",
              "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Shawshank Redemption is without a doubt on...</td>\n",
              "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I believe that this film is the best story eve...</td>\n",
              "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>**Yes, there are SPOILERS here**This film has ...</td>\n",
              "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>At the heart of this extraordinary movie is a ...</td>\n",
              "      <td>In 1947, Andy Dufresne (Tim Robbins), a banker...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f0bee1f8-68a1-4bea-a1ea-bced9c567c93')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f0bee1f8-68a1-4bea-a1ea-bced9c567c93 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f0bee1f8-68a1-4bea-a1ea-bced9c567c93');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                              review  \\\n",
              "0  In its Oscar year, Shawshank Redemption (writt...   \n",
              "1  The Shawshank Redemption is without a doubt on...   \n",
              "2  I believe that this film is the best story eve...   \n",
              "3  **Yes, there are SPOILERS here**This film has ...   \n",
              "4  At the heart of this extraordinary movie is a ...   \n",
              "\n",
              "                                            synopsis  label  \n",
              "0  In 1947, Andy Dufresne (Tim Robbins), a banker...   True  \n",
              "1  In 1947, Andy Dufresne (Tim Robbins), a banker...   True  \n",
              "2  In 1947, Andy Dufresne (Tim Robbins), a banker...   True  \n",
              "3  In 1947, Andy Dufresne (Tim Robbins), a banker...   True  \n",
              "4  In 1947, Andy Dufresne (Tim Robbins), a banker...   True  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_df = pd.read_csv(preprocessed_file, nrows=rows_count)\n",
        "data_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ug07H2DIAskH"
      },
      "outputs": [],
      "source": [
        "def text_to_word_list(text):\n",
        "  ''' Pre process and convert texts to a list of words '''\n",
        "  text = str(text)\n",
        "  text = text.lower()\n",
        "\n",
        "  # Clean the text\n",
        "  text = sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "  text = sub(r\"what's\", \"what is \", text)\n",
        "  text = sub(r\"\\'s\", \" \", text)\n",
        "  text = sub(r\"\\'ve\", \" have \", text)\n",
        "  text = sub(r\"can't\", \"cannot \", text)\n",
        "  text = sub(r\"n't\", \" not \", text)\n",
        "  text = sub(r\"i'm\", \"i am \", text)\n",
        "  text = sub(r\"\\'re\", \" are \", text)\n",
        "  text = sub(r\"\\'d\", \" would \", text)\n",
        "  text = sub(r\"\\'ll\", \" will \", text)\n",
        "  text = sub(r\",\", \" \", text)\n",
        "  text = sub(r\"\\.\", \" \", text)\n",
        "  text = sub(r\"!\", \" ! \", text)\n",
        "  text = sub(r\"\\/\", \" \", text)\n",
        "  text = sub(r\"\\^\", \" ^ \", text)\n",
        "  text = sub(r\"\\+\", \" + \", text)\n",
        "  text = sub(r\"\\-\", \" - \", text)\n",
        "  text = sub(r\"\\=\", \" = \", text)\n",
        "  text = sub(r\"'\", \" \", text)\n",
        "  text = sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "  text = sub(r\":\", \" : \", text)\n",
        "  text = sub(r\" e g \", \" eg \", text)\n",
        "  text = sub(r\" b g \", \" bg \", text)\n",
        "  text = sub(r\" u s \", \" american \", text)\n",
        "  text = sub(r\"\\0s\", \"0\", text)\n",
        "  text = sub(r\" 9 11 \", \"911\", text)\n",
        "  text = sub(r\"e - mail\", \"email\", text)\n",
        "  text = sub(r\"j k\", \"jk\", text)\n",
        "  text = sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "  text = text.split()\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sKZ8iyG0AZAd"
      },
      "outputs": [],
      "source": [
        "def generate_vocab():\n",
        "  print('Generating vocabulary')\n",
        "\n",
        "  global vocab_size, vocab\n",
        "  global word_to_id, id_to_word, word_to_count\n",
        "  global data_df\n",
        "\n",
        "  stops = set(stopwords.words('english'))\n",
        "\n",
        "  # Iterate over required sequences of provided dataset\n",
        "  for index, row in data_df.iterrows():\n",
        "      # Iterate through the text of both questions of the row\n",
        "      for col in sequence_cols:\n",
        "          s2n = []  # Sequences with words replaces with indices\n",
        "          for word in text_to_word_list(row[col]):\n",
        "              # Remove unwanted words\n",
        "              if word in stops:\n",
        "                  continue\n",
        "\n",
        "              if word not in vocab:\n",
        "                  vocab.add(word)\n",
        "                  word_to_id[word] = vocab_size\n",
        "                  word_to_count[word] = 1\n",
        "                  s2n.append(vocab_size)\n",
        "                  id_to_word[vocab_size] = word\n",
        "                  vocab_size += 1\n",
        "\n",
        "              else:\n",
        "                  word_to_count[word] += 1\n",
        "                  s2n.append(word_to_id[word])\n",
        "\n",
        "          # Replace |sequence as word| with |sequence as number| representation\n",
        "          data_df.at[index, col] = s2n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ2KuP0PP1x-",
        "outputId": "369b53bc-6850-466f-e032-d5da9705d0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating vocabulary\n",
            "Gen vocab in 7.438301189740499 min\n"
          ]
        }
      ],
      "source": [
        "start = time()\n",
        "generate_vocab()\n",
        "data_df.head()\n",
        "print(f\"Gen vocab in {(time() - start) / 60} min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "RAoRRslIEiBP"
      },
      "outputs": [],
      "source": [
        "def preprocess_data():\n",
        "  print('Building training data set')\n",
        "  \n",
        "  global x_train, x_val, y_train, y_val\n",
        "  global x_test, y_test\n",
        "\n",
        "  data_size = len(data_df)  \n",
        "\n",
        "  X = data_df[sequence_cols]\n",
        "  Y = data_df[score_col]\n",
        "\n",
        "  x_rem, x_test, y_rem, y_test = train_test_split(X, Y, train_size=test_ratio, stratify=Y, random_state=random_state)\n",
        "  x_train, x_val, y_train, y_val = train_test_split(x_rem, y_rem, train_size=train_ratio, stratify=y_rem, random_state=random_state)\n",
        "\n",
        "  # Split to lists\n",
        "  x_train = [x_train[column] for column in sequence_cols]\n",
        "  x_val = [x_val[column] for column in sequence_cols]\n",
        "  x_test = [x_test[column] for column in sequence_cols]\n",
        "\n",
        "  # Convert labels to their numpy representations\n",
        "  y_train = y_train.values\n",
        "  y_val = y_val.values\n",
        "  y_test = y_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEoUmoUGEsCL",
        "outputId": "82fa3a75-1c18-4a2a-bcc0-62d5933c6ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building training data set\n",
            "Length X_train: 72000\n",
            "Length X_val: 8000\n",
            "Length X_test: 20000\n"
          ]
        }
      ],
      "source": [
        "preprocess_data()\n",
        "print('Length X_train: ' + str(len(x_train[0])))\n",
        "print('Length X_val: ' + str(len(x_val[0])))\n",
        "print('Length X_test: ' + str(len(x_test[0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "qJsNpx5gGf80"
      },
      "outputs": [],
      "source": [
        "max_len = 1024\n",
        "def pad_seq():\n",
        "  print('Padding sequences')\n",
        "\n",
        "  global max_len\n",
        "\n",
        "  if max_len == 0:\n",
        "      max_len = max(\n",
        "          max(len(seq) for seq in x_train[0]),\n",
        "          max(len(seq) for seq in x_train[1]),\n",
        "          max(len(seq) for seq in x_val[0]),\n",
        "          max(len(seq) for seq in x_val[1]),\n",
        "          max(len(seq) for seq in x_test[0]),\n",
        "          max(len(seq) for seq in x_test[1]))\n",
        "  print(f\"max_len: {max_len}\")\n",
        "  # Zero padding\n",
        "  for dataset, side in itertools.product([x_train, x_val, x_test], [0, 1]):\n",
        "      if max_len: dataset[side] = pad_sequences(dataset[side], maxlen=max_len)\n",
        "      else : dataset[side] = pad_sequences(dataset[side])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sagPxQAIGnDR",
        "outputId": "dd8325e8-1bc8-4dd0-b630-f2486122b4a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1367.2526944444444\n",
            "5746\n",
            "Padding sequences\n"
          ]
        }
      ],
      "source": [
        "print(np.mean([len(seq) for seq in x_train[0]]))\n",
        "max_len_tmp = max(\n",
        "          max(len(seq) for seq in x_train[0]),\n",
        "          max(len(seq) for seq in x_train[1]),\n",
        "          max(len(seq) for seq in x_val[0]),\n",
        "          max(len(seq) for seq in x_val[1]),\n",
        "          max(len(seq) for seq in x_test[0]),\n",
        "          max(len(seq) for seq in x_test[1]))\n",
        "print(max_len_tmp)\n",
        "pad_seq()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-07T06:26:00.924875Z",
          "iopub.status.busy": "2023-05-07T06:26:00.924356Z",
          "iopub.status.idle": "2023-05-07T06:26:00.930939Z",
          "shell.execute_reply": "2023-05-07T06:26:00.929555Z",
          "shell.execute_reply.started": "2023-05-07T06:26:00.924832Z"
        },
        "id": "KFEBs9uA7cY0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from gensim.models import KeyedVectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "8lcUKtP8Ppt7"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 300\n",
        "\n",
        "def get_embedding_matrix(word_index):\n",
        "  # https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g\n",
        "  google_embeddings = '/content/drive/MyDrive/UNIST/deep-learning/GoogleNews-vectors-negative300.bin.gz'\n",
        "  word2vec = KeyedVectors.load_word2vec_format(google_embeddings, binary=True)\n",
        "\n",
        "  # Prepare Embedding Matrix.\n",
        "  embedding_matrix = np.zeros((len(word_index)+1, embedding_dim))\n",
        "\n",
        "  for word, i in word_index.items():\n",
        "  # words not found in embedding index will be all-zeros.\n",
        "    if word not in word2vec.key_to_index:\n",
        "      continue\n",
        "    embedding_matrix[i] = word2vec.get_vector(word)\n",
        "\n",
        "  del word2vec\n",
        "  return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5fayxcHHSAR",
        "outputId": "55d920e5-0c7e-4cc0-de25-1bc2b8362031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building Embedding Matrix\n"
          ]
        }
      ],
      "source": [
        "print('Building Embedding Matrix')\n",
        "embedding_matrix = get_embedding_matrix(word_to_id)\n",
        "embedding_size = embedding_matrix.shape[1]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug7xFXlxTpNB"
      },
      "source": [
        "## Manhatten LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "HcyMuEoHTsXR"
      },
      "outputs": [],
      "source": [
        "hidden_size = 50\n",
        "adadel_learning_rate = 0.66\n",
        "adam_learning_rate = 1e-4 # 0.001\n",
        "# dropout_rate = 0.1\n",
        "batch_size = 64\n",
        "num_iters = 5 # number of epochs\n",
        "\n",
        "PATIENCE = 4\n",
        "VERBOSE = 1\n",
        "filepath = '/content/drive/My Drive/Colab Notebooks/saved_models_manhtn/lr1-san-adam--{epoch:02d}-{val_loss:.5f}.hdf5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF72ZEL9T67I",
        "outputId": "86b7f17d-664e-414b-9717-ba6481e2f388"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training samples        : 72000\n",
            "Number of validation samples      : 8000\n",
            "Number of testing samples         : 20000\n",
            "Maximum sequence length           : 1024\n"
          ]
        }
      ],
      "source": [
        "print('Number of training samples        :', len(x_train[0]))\n",
        "print('Number of validation samples      :', len(x_val[0]))\n",
        "print('Number of testing samples         :', len(x_test[0]))\n",
        "print('Maximum sequence length           :', max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "uXU91bvbVIYX"
      },
      "outputs": [],
      "source": [
        "def exponent_neg_manhattan_distance(x, hidden_size=50):\n",
        "  ''' Helper function for the similarity estimate of the LSTMs outputs '''\n",
        "  return K.exp(-K.sum(K.abs(x[:,:hidden_size] - x[:,hidden_size:]), axis=1, keepdims=True))\n",
        "\n",
        "def exponent_neg_cosine_distance(x, hidden_size=50):\n",
        "  ''' Helper function for the similarity estimate of the LSTMs outputs '''\n",
        "  leftNorm = K.l2_normalize(x[:,:hidden_size], axis=-1)\n",
        "  rightNorm = K.l2_normalize(x[:,hidden_size:], axis=-1)\n",
        "  return K.exp(K.sum(K.prod([leftNorm, rightNorm], axis=0), axis=1, keepdims=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HK8y52zoVfwc",
        "outputId": "2fc2240e-8d77-445c-923c-88f908a14fd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adadelta.py:82: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/optimizers/legacy/adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "opt1 = keras.optimizers.Adadelta(lr=adadel_learning_rate, clipnorm=1.25)\n",
        "opt2 = keras.optimizers.Adam(lr=adam_learning_rate)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, \n",
        "                             monitor='val_loss', \n",
        "                             verbose=VERBOSE,\n",
        "                             save_best_only=True, \n",
        "                             mode='auto')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=PATIENCE,\n",
        "                               verbose=VERBOSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "1V_H2uNJJLHh"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "GzmGIM7yWbaR"
      },
      "outputs": [],
      "source": [
        "def get_manhattan_lstm_model(embedding_matrix, embedding_size, lstm_layers, opt):\n",
        "  embed_layer = Embedding(output_dim=embedding_size, input_dim=vocab_size+1, input_length=max_len, trainable=False)\n",
        "  embed_layer.build((None,))\n",
        "  embed_layer.set_weights([embedding_matrix])\n",
        "\n",
        "  seq_1 = Input(shape=(max_len,), dtype='int32', name='sentence_1')\n",
        "  seq_2 = Input(shape=(max_len,), dtype='int32', name='sentence_2')\n",
        "\n",
        "  input_1 = embed_layer(seq_1)\n",
        "  input_2 = embed_layer(seq_2)\n",
        "\n",
        "  l1 = LSTM(units=hidden_size)\n",
        "\n",
        "  l1_out = l1(input_1)\n",
        "  l2_out = l1(input_2)\n",
        "\n",
        "  concats = concatenate([l1_out, l2_out], axis=-1)\n",
        "\n",
        "  main_output = Lambda(exponent_neg_manhattan_distance, output_shape=(1,))(concats)\n",
        "  model = Model(inputs=[seq_1, seq_2], outputs=[main_output])\n",
        "\n",
        "  model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lh04KE-TJx3G",
        "outputId": "90dace16-0cb5-4a5e-a795-0faad63b9a26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " sentence_1 (InputLayer)        [(None, 1024)]       0           []                               \n",
            "                                                                                                  \n",
            " sentence_2 (InputLayer)        [(None, 1024)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding_3 (Embedding)        (None, 1024, 300)    36542400    ['sentence_1[0][0]',             \n",
            "                                                                  'sentence_2[0][0]']             \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  (None, 50)           70200       ['embedding_3[0][0]',            \n",
            "                                                                  'embedding_3[1][0]']            \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 100)          0           ['lstm_3[0][0]',                 \n",
            "                                                                  'lstm_3[1][0]']                 \n",
            "                                                                                                  \n",
            " lambda_3 (Lambda)              (None, 1)            0           ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 36,612,600\n",
            "Trainable params: 70,200\n",
            "Non-trainable params: 36,542,400\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "man_lstm_model = get_manhattan_lstm_model(embedding_matrix, embedding_size, hidden_size, opt2)\n",
        "man_lstm_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRLaHtyiaQQL",
        "outputId": "34a0762d-89e6-43fe-f120-441732256bf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " 523/1125 [============>.................] - ETA: 21:28 - loss: 0.6814 - accuracy: 0.7471"
          ]
        }
      ],
      "source": [
        "training_start_time = time()\n",
        "man_lstm_model_ = man_lstm_model.fit(x_train, \n",
        "                                 y_train, \n",
        "                                 validation_data=(x_val, y_val),\n",
        "                                 epochs=num_iters,\n",
        "                                 callbacks=[checkpoint, early_stopping], \n",
        "                                 batch_size=batch_size, \n",
        "                                 verbose=1)\n",
        "\n",
        "print(\"Training time finished.\\n{} epochs in {}\".format(num_iters, datetime.timedelta(seconds=time()-training_start_time)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-04-26T03:29:04.759946Z",
          "iopub.status.busy": "2023-04-26T03:29:04.759534Z",
          "iopub.status.idle": "2023-04-26T03:30:41.318684Z",
          "shell.execute_reply": "2023-04-26T03:30:41.317542Z",
          "shell.execute_reply.started": "2023-04-26T03:29:04.759899Z"
        },
        "id": "mT9Ja0zA7cY1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# stratified model\n",
        "model_path = '/content/drive/MyDrive/Colab Notebooks/saved_models_manhtn/lr1-san-adam--12-0.17527.hdf5'\n",
        "\n",
        "man_lstm_model.load_weights(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-04-26T03:30:41.320755Z",
          "iopub.status.busy": "2023-04-26T03:30:41.320251Z",
          "iopub.status.idle": "2023-04-26T03:32:09.376154Z",
          "shell.execute_reply": "2023-04-26T03:32:09.375111Z",
          "shell.execute_reply.started": "2023-04-26T03:30:41.320706Z"
        },
        "id": "iYRmRIDc7cY1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(1)\n",
        "plt.plot(man_lstm_model_.history['accuracy'])\n",
        "plt.plot(man_lstm_model_.history['val_accuracy'])\n",
        "plt.title('Manhattan LSTM Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-04-26T03:32:09.378356Z",
          "iopub.status.busy": "2023-04-26T03:32:09.37755Z",
          "iopub.status.idle": "2023-04-26T03:32:13.565172Z",
          "shell.execute_reply": "2023-04-26T03:32:13.56417Z",
          "shell.execute_reply.started": "2023-04-26T03:32:09.378303Z"
        },
        "id": "tY0T9C3P7cY2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(2)\n",
        "plt.plot(man_lstm_model_.history['loss'])\n",
        "plt.plot(man_lstm_model_.history['val_loss'])\n",
        "plt.title('Manhattan LSTM Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='upper left')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-04-26T03:32:13.567178Z",
          "iopub.status.busy": "2023-04-26T03:32:13.566486Z",
          "iopub.status.idle": "2023-04-26T03:32:17.304072Z",
          "shell.execute_reply": "2023-04-26T03:32:17.303009Z",
          "shell.execute_reply.started": "2023-04-26T03:32:13.567136Z"
        },
        "id": "kVSdJOiI7cY2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "score = man_lstm_model.evaluate(x_test,\n",
        "                            y_test,\n",
        "                            batch_size=batch_size)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKDcqU8VLcR_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2023-04-26T03:32:17.307903Z",
          "iopub.status.busy": "2023-04-26T03:32:17.307564Z",
          "iopub.status.idle": "2023-04-26T03:32:18.160466Z",
          "shell.execute_reply": "2023-04-26T03:32:18.159437Z",
          "shell.execute_reply.started": "2023-04-26T03:32:17.307871Z"
        },
        "id": "EdUB2fFX7cY3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "y_pred = man_lstm_model.predict(x_test)\n",
        "y_pred = [0 if x < 0.5 else 1 for x in y_pred]\n",
        "y_test_1hot = [0 if not x else 1 for x in y_test]\n",
        "print(classification_report(y_test_1hot, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "id": "veOeCzlQ7cY8"
      },
      "outputs": [],
      "source": [
        "def word_to_sequence(tokens: list) -> list:\n",
        "  result = list()\n",
        "  stops = set(stopwords.words('english'))\n",
        "  for token in tokens:\n",
        "    if token in stops:\n",
        "      continue\n",
        "    if token in vocab:\n",
        "      result.append(word_to_id[token])\n",
        "  return result\n",
        "\n",
        "def get_spoiler_prob(synopsis, review) -> float:\n",
        "  #pd.DataFrame({'synopsis': [synopsis], 'review': [review]})\n",
        "  # print('synop')\n",
        "  s_tokens = text_to_word_list(synopsis)\n",
        "  s_seq = pad_sequences([word_to_sequence(s_tokens)], maxlen=max_len)\n",
        "  # print('review')\n",
        "  r_tokens = text_to_word_list(review)\n",
        "  r_seq = pad_sequences([word_to_sequence(r_tokens)], maxlen=max_len)\n",
        "  y_pred = man_lstm_model.predict([s_seq, r_seq])\n",
        "  return y_pred[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySycHRQldQ9p"
      },
      "outputs": [],
      "source": [
        "def test_spoiler():\n",
        "  synopsis = \"Jack Ryan (Ford) is on a \\\"working vacation\\\" in London with his family. He has retired from the CIA and is a Professor at the US Naval Academy. He is seen delivering a lecture at the Royal Naval Academy in London.Meanwhile, Ryan's wife Cathy and daughter Sally are sightseeing near Buckingham Palace. Sally and Cathy come upon a British Royal Guard, and Sally tries to get the guard to react by doing an improvised tap dance in front of him. She's impressed when the guard, trained to ignore distraction, doesn't react at all, and they leave.As Sally and Cathy walk away from the guard, en route to rendezvous with Ryan, they walk by a stolen cab, in which sit three Ulster Liberation Army terrorists: Kevin O'Donnell, the driver, as well as Sean Miller (Sean Bean) and his younger brother Patrick. The three are loading bullets into their guns as they prepare to carry out a scheduled ambush on Lord William Holmes, British Secretary of State for Northern Ireland and a distant member of the British Royal Family (the cousin of the Queen Mother). As they finish loading their weapons, another terrorist, Annette, radios to them that Lord Holmes is leaving the palace with his wife and son.As Lord Holmes's car leaves the palace, the terrorists' car falls in line behind him. They follow the car, headed for the ambush point. As they drive, O'Donnell and the Miller brothers don ski masks.Meanwhile, Ryan is about to cross the street to meet with his wife and daughter. He arrives at the same time that Lord Holmes's car is passing through the area.Suddenly, another cab, parked on the side of the road, driven by Annette, pulls out and swerves in front of Lord Holmes's vehicle. Simultaneously, O'Donnell's vehicle swerves to a stop behind the car. The Millers and another accomplice jump out and quickly plant a bomb underneath the chauffeured car's engine. Ryan sees what's going on and hastily gets his family to cover just as the bomb is detonated. Moments later, Sean and another accomplice begin shooting into the car, riddling Lord Holmes's driver and bodyguard with bullet. The onslaught of bullets does not kill Lord Holmes, who is currently using his body to shield his family. Sean marches over to the rear door and orders Lord Holmes out of the car at gunpoint. Ryan, unable to stand being just a bystander, immediately breaks cover, runs up behind Miller, and disarms him. As Ryan grabs Sean's pistol, he gets shot in the left shoulder by another terrorist. He shoots one of the other terrorists in the shoulder. Patrick attempts to flee, but Ryan fatally shoots him in the chest. Seeing two of the royal guards racing towards the scene, the remaining terrorists quickly get back in their cars and drive off, leaving Sean to be captured when the authorities arrive. They retreat back to a warehouse, where they change out license plates.While recovering, Ryan is called to testify against Miller as a witness. Subsequently, Miller is convicted on all charges and sentenced to life in prison. Ryan is awarded the order of Knight Commander of the Victorian Order, and eventually returns to the United States.On the possibility that Miller's ULA comrades might try to liberate him, the authorities take no chances. To that extent, they set up decoy convoys on the day that Miller is to be transferred to Albany Prison on the Isle of Wight. However, someone manages to tip off the ULA as to which convoy is carrying Miller. Miller's motorcade is in transit when it comes to a stop at a drawbridge. The raised bridge, however, is a trap meant to block them in. Moments after the convoy comes to a stop, Miller's comrades attack, using rocket launchers to blow up the cars at the front and rear of the convoy. They then march up to the prison van and order the guards out at gunpoint by taking the bridge operator hostage and threatening to shoot him. One of the guards hesitates and is shot fatally. The other officer and the inspector are pulled out, thrown on the ground and forced to lie on their stomachs. O'Donnell hands Miller a pistol, with which he coldly executes both officers and the bridge operator by shooting them in the backs of their heads. They then depart the scene.Miller and his companions flee on a cargo ship from Britain to Libya, to prepare for their next kidnapping attempt on Lord Holmes. Miller however, cannot shake his anger towards Ryan for killing his younger brother and persuades several members of his entourage to accompany him to the United States on a short mission targeting Ryan and his family.Miller travels to the United States, accompanied by Annette, comrade Ned Clark, and a fourth henchman. Annette and Clark travel to the United States Naval Academy to ambush Ryan as he's leaving work. Ryan notices Clark idling nearby. Clark casually walks away, but Ryan clearly unnerved, then gets even more nervous as he hears a car engine starting. His suspicions are well warranted-as he continues walking down the street, he looks in the reflection of a parked van's rearview door and sees that Clark, and the stolen car driven by Annette, are following him. Ryan pretends not to see them until he's walking past a parked panel truck, at which point he ducks behind the truck. Clark draws a silenced pistol and prepares to corner Ryan, but Ryan attacks him first. Clark quickly gets the upper hand and throws Ryan to the curb. He grabs his pistol and is about to shoot Ryan when he's shot dead himself by a US Marine sentry. Annette quickly drives away in her Jeep. Ryan, realizing that Miller is going to target Cathy and Sally, jumps into his car and drives off.Simultaneously, Miller and the other henchman follow Cathy as she picks up Sally from school, with Miller riding shotgun. They prepare to follow the two, but are temporarily held up by a crossing guard. Once the crossing guard clears, they pursue her to US Highway 50. Ryan tries to frantically call Cathy on his car phone, but she is busy answering phone calls from the hospital. As he's trying to connect with her, Miller and his henchman recklessly weave in and out of traffic to catch up with Cathy. Ryan eventually gets through to Cathy and tells her to get off the highway and find the nearest police station. Unfortunately, just as the call ends, Miller's van comes charging up on her using the left shoulder. Miller moves to the backseat of the van, grabs a submachine gun, and slides open the door. Another car momentarily delays him, but once he has a clear aim, Miller opens fire, spraying Cathy's car with bullets. A multicar pileup ensues as Cathy loses control of her car and crashes head-on into a concrete barrier. Ryan, who has found himself stuck in traffic headed in the other direction, sees the smoke from the crash and realizes the worst.Cathy and Sally are airlifted to a nearby hospital for treatment. Enraged over the near-loss of his family, Ryan decides to go back to work for the CIA, having earlier rejected the appeal of his former superior, Vice Admiral James Greer (James Earl Jones).Ryan's tireless work leads him to conclude that Miller has taken refuge in a training camp, one of many located in Libya. He also determines that a recent new arrival at the camp may be one of O'Donnell's English informants, Dennis Cooley. Ryan makes his recommendations to his superiors at the CIA. Greer invites Jack to a live feed of an SAS strike team attack on the camp. Everyone in the camp is eliminated but unbeknownst to the CIA and Ryan, Miller and his companions have already fled the camp and are on their way to the US to stage their next attack on Lord Holmes.Lord Holmes decides to visit Ryan at his home to formally present his KCVO. With the aid of Lord Holmes' traitorous assistant, Miller's group tracks Holmes to this location, kills the Diplomatic Security Service agents and Maryland state troopers guarding the house, and attempts once more to kidnap Lord Holmes. Ryan leads Holmes and his family to safety while he attempts to lure Miller and his companions away from his home.The FBI Hostage Rescue Teams are scrambled to pick up Holmes. Upon realising that Ryan is leading them away from Holmes, Miller's companions try to persuade Miller to turn around, but an enraged and deranged Miller kills his terrorist companions and continues his pursuit of Ryan. Ryan and Miller fight hand to hand; Miller is killed when Ryan impales him backward on a boat anchor, and his body is obliterated in the subsequent explosion of the craft.Credits roll just after Caroline Ryan learns the gender of the child she is going to have, and before she tells Jack and Sally.\"\n",
        "  review = \"Sally and Jack are both alive in the end.\"\n",
        "  prob = get_spoiler_prob(synopsis, review)\n",
        "  print(f\"synopsis: {synopsis}\")\n",
        "  print(f\"review: {review}\")\n",
        "  print(f\"prob: {prob}\")\n",
        "\n",
        "test_spoiler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kR1qdRZ5ehcM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
